介绍一下自己的三段项目经历

涉及到的技术难点

# 第一家 没啥说的

# 第二家 远程培训平台

## 自己基于flowable做二次开发，集成表单设计器，流程设计器，

### **AOP操作日志记录**

### 抽象模型

### **sql执行错误生产数据丢失**

- 确认要恢复的 binlog 的开始和结束
  - 查该阶段期间的操作记录，有一个流程更新了数据
  - Github 上有个开源项目 binlog2sql，可以将 binlog 的 event 翻译成 SQL 语句，也可以翻译成反向 SQL
  - 在仿真环境进行测试和回复保证其他业务不受影响
- 根据 binlog 的开始和结束，确认数据恢复方案，以及是否需要需要排除在这个时间段发生的其他干扰数据
  - binlog：记录所有写操作
  - redolog：【**大小固定，循环写入**】记录对页数据的变更，只记录事务**对数据页做了哪些修改**，这样就能完美地解决性能问题了(相对而言文件更小并且是**顺序IO**)，重启时候进行检查恢复，磁盘中**数据页的LSN**，如果数据页的LSN小于日志中的LSN，则会从checkpoint开始恢复
  - undolog：版本连

### **mysql如何实现MVCC**

- Undo-log日志的版本链 + 数据表上的隐藏字段
- **每开启一个事务都会形成一个读视图**
  - 创建该视图时的 事务id
  - 创建该视图时的 活跃事务id集合
  - 创建该视图时的 最小活跃事务id
  - 创建该视图时的 下一个理论id
- **确定读取哪个版本的数据**
  - **读取的事务id** < 最小活跃事务id；该版本对当前事务可见
  - **读取的事务id** > 最大活跃事务id；该版本对当前事务不可见
  - 最小活跃事务id < **读取的事务id** < 最大活跃事务id
    - 读取的事务id在活跃事务id集合，不可见
    - 读取的事务id不在活跃事务id集合，可见
- **不同隔离级别如何实现**
  - 脏读：读操作不加锁。
  - 幻读：写操作加排他锁，读操作使用`MVCC`，但**每次`select`都生成读视图**。
  - 可重复读/：写操作加间隙锁，读操作依旧采用`MVCC`机制，但**一次事务中只生成一个读视图**。
  - 序列化/`Serializable`：所有**写操作加临键锁（具备互斥特性）**，所有读操作加共享锁。

## 体育彩票远程培训平台（课程上架，选课，学课）

### **学习记录更新服务单进程synchronized关键字，ReentrantLock**；

### **课程选课服务多进程下采用分布式锁Redission解决对同一资源访问**

- **加锁与过期时间原子性问题**
- **公平和非公平性**
- **锁续期**：自己不设置有效期时，leaseTime会被默认设为-1时
- 利用信号量和PubSub功能实现等待、唤醒，获取锁失败的**重试机制**
- 多个RLock对象组成一把锁，全部返回成功则加锁成功，保证了用MutiLock解决主从一致性问题
- 多线程情况下**加线程唯一标识**来解决加锁解锁不一致的问题

### 学习记录更新导致的线上OOM

- 测试环境调小堆内存场景复现
- 内存溢出后生成dump文件
- MAT解析dump文件
- **定位大对象**
- 点击支配树（dominator tree），看大对象被哪个线程调用。这里可以看到是被主线程调用
- 点击概述图标（thread_overview），看线程的方法调用链和堆栈信息，查看大对象所属类和第几行，定位到具体代码，解决问题

# 第三家

## 中国联通宽带数据大批量接入接入

### 大批量数据读取

- NIO大文件数据拆分（确定数据的起始和结束位置，然后通过固定标识符/r/n进行修正；采用缓冲区来进行数据读取，不是一次性加载到内存）
- 自己封装batch数据批量插入模板进行数据合并，
- 多线程进行数据插入，CPU核心数量*2 +2 个线程

### 删除（某一个id数据）和插入同时进行导致的Mysql死锁

- 问题查找过程

  ```
   # 确认有没有锁等待:
   show status like 'innodb_row_lock%';
   select * from information_schema.innodb_trx;
   
   # 查询锁等待详细信息
   select * from sys.innodb_lock_waits; ----> blocking_pid(锁源的连接线程)
   
   # 通过连接线程ID找SQL线程语句
   select * from performance_schema.threads;
   
   # 通过SQL线程找到SQL语句
   select * from performance_schema.events_statements_history;
  ```

- 测试验证，监控

- T1 在执行插入语句时，需要等待 T2- T101 上持有的 Gap Locks 释放

- T2 - T6 可能同时执行插入语句，然后进行死锁检测，事务回滚

- 但在**死锁检测的过程中**还会有新事务 (T101 - T 200) 获取到 Gap Locks，造成锁等待队列中的事务越来越多

### 选错索引导致的线上慢查询事故（5000w数据）

```
 select *
  from
    sample_table
  where
      1 = 1
      and (city_id = 565)
      and (type = 13)
  order by
    id desc
  limit
    0, 1
```

#### 问题原因排查（定位为选错索引）

**有idx_city_id_type联合索引和idx_1索引的」**，我们的查询条件是city_id和type，这两个索引都是能走到的，但是认为扫描行数较多【**mysql默认将limit下的扫描行数作为索引扫描的依据**；**MySQL优化器认为在limit 1的情况下，走主键索引扫描1800行左右还不用排序，使用联合索引扫描40000多左右，还需要排序**】

#### Explain分析SQL语句

Explain比较重要的字段有：

- select_type : 查询类型，有简单查询、联合查询、子查询等
- key : 使用的索引
- rows : 预计需要扫描的行数
- **Extra**
  - **using filesort**：mysql不能用索引完成的排序
  - **using temporary**：查询排序使用了临时表（group by，sort）
  - **using index**：索引用于数据行查找
  - **using where**：索引用于索引键值查找
  - **using index condition**：查找使用了索引，不需要回表查询，因为要过滤的字段在索引中【mysql5.6之后支持索引下推】
    - 5.6之前，先找，回表查数据筛选，然后在进行筛选；5.6之后直接用索引列进行筛选

#### 解决方案

- **强制选择索引：force index**———-暴漏在外的；索引名变化了，或者没有这个索引了，代码就要反复修改。属于硬编码
- **索引要考虑 order by 的字段**

### 深度分页问题

```
 select a,b,c,d from a where date > '' limit 100,3
```

- explain 之后发现 type range

```
 select a,b,c,d from a where date > '' limit 1000000,3
```

- explain 之后发现 type ALL Extra：where filesort

如何解决：

- Id自增的情况下，采用id限定；或者添加其他列保证自增属性
- 使用覆盖索引内连接，查询的列都是索引列（**连接的时候会产生临时表**）

## 订单系统

### Redis缓存

- 为什么要用Redis作为缓存（减轻页面访问量）
  - Redis高性能网络模型（事件分发机制）
- 商品超卖问题解决：Redis扣减库存 + mysql乐观锁
- 缓存数据一致性
- 支付消息幂等
  - **生成唯一消息ID**
  - **存储消息ID到Redis**
  - **检查消息是否已处理**
- Redis实现**请求限流**；自定义注解，使用切面集成自定义请求方法，然后进行对应的**服务降级**
- Redis**底层数据结构和编码**
- Redis缓存数据一致性（商品后台修改属性，商品**首页数据浏览的时候进行缓存**）
- **Redis去中心化分片集群实现数据存储**（高可用几种机制优缺点）
- Redis底层数据结构和编码
- Redis存储防止接口盗刷
  - 前端验证码
  - 基于（用户+url）限制访问数量
  - 基于（用户+url）分发token令牌

### RocketMq

- 为什么选择rocketmq
  - kafka：分布式流处理平台，具有高吞吐、低延迟和可靠性强的特点。它适用于大规模实时数据处理场景
  - RabbitMQ是一个开源的消息代理软件，支持多种消息协议和队列类型。它具有良好的可靠性、可扩展性和易用性，适用于各种规模的项目
  - **RocketMQ**：实现消息顺序性
- 实现订单消息有序（自己实现的话）
  - 发送有序
  - 全局顺序（对应一个topic对应一个消费者单线程消费）
  - 局部有序
    - 按照订单号进行哈希取余队列长度的方式将统一业务的消息同步发送到一个消息队列
    - 消费者采用拉取的方式，每次拉取的时候【锁定messagequeue】确定只有一个队列的消息可以被拉取
    - 发布消费消息，然后多线程进行消费，消费的时候获取每一个队列的锁，保证同一时刻只有一个队列的消息被消费
- 异步发送通知
- 主动拉取（秒杀生成订单），限制流量到mysql

### nginx应用前流量转发

- 负载均衡
- lvs高可用
- 流量转发和回退

### gateway实现流量转发【Spring Cloud里边的Zuul网关】

### AOP

- **日志跟踪和记录**
- 安全检查

### mysql

- 订单表数据结构设计（3500w）

- 垂直拆分

  - 订单基础信息（订单号，状态，渠道，下单时间，） +
  - 产品明细（数量、单价、运费）
  - 折扣表（使用的优惠券）
  - 配送信息（物流单号、物流状态）
  - 支付信息（支付流水、金额、运费、优惠）

- 水平拆分

  - 10个数据库 + 每个数据库存30天订单 + 每天分 100张表

    按照哪个字段分库

    订单号 ： user_id + 距离上线时间戳 + 趋势递增id

    user_id 计算 hash **确定最后落在哪个数据库** ；**解析时间戳**确定最终落在 **哪100张表里边** ；**user_id 对100取模** 确定落在哪张表

    一个订单库的数据在一个数据库，**不用走分布式事务**；一个订单的数据在一个表，**支持单个user_id的批量查询**；**保留30天的数据**，历史订单数据存到离线存储用于**离线分析**

- 根绝用户id集合之外的条件查询

  - 监听 binLog 发送消息 到mq自己消费消息写入到 es
  - Es 按照 天分索引，每个表对应不同的索引前缀，加定时脚本每天滚动创建新索引
  - 查询的时候指定 时间范围（确定索引范围，查多个索引进行汇总排序）

- 别的服务订阅订单数据

  - 商家按照**商家id进行数据分表**，收到订单数据后**批量跑延迟任务**，调用快递三方接口下单
  - 订单信息会略微有延迟

- 配送服务怎么实现

  - 下单成功后，快递信息记录到商家侧表，往订单服务发消息更新（快递单号查）
  - 加回调接口，物流信息更新后这边同步更新
  - 物流轨迹本地缓存（3小时半天）
  - 订单签收之后发送消息，变更订单状态，定时任务完成未主动结束的订单

- 结束订单怎么实现

  - 任务调度，分片到多个实例扫表，按照创建时间批量查到期时间（目前小时级别处理就行）

- 索引选择和设计

  - 查找和排序
    - 二叉树（左小右大，最多两个叶子结点，可以二分查找，容易线性链表）
    - 平衡树（旋转维持每个节点左右子树高度差不超过1，绝对平衡，查找性能 O(log n) ，插入和删除使用旋转操作相对复杂，需要更多的计算资源）
    - 红黑树（颜色和旋转操作来维持平衡，追求大致平衡，只需要最多三次旋转就能达到平衡，单路）
    - B树（平衡的多路搜索树，其中每个节点可以有多个子节点。B树的阶（即每个节点允许的最大子节点数）决定了树的平衡性和查找性能）
    - B+树（所有数据都存储在叶子节点中，并且叶子节点之间通过指针链接。这使得范围查询和顺序访问更为高效）
  - 区分度大的列建索引
  - 复合索引，左前缀，**区分度的字段放前面**
  - **排序和分组字段也尽量创建索引**
  - 覆盖索引

### nacos

- 服务发现和注册
- 健康检查
- 动态配置管理

### jvm调优

- 测试环境模拟，配置符合大小的堆内存

  - -Xms：初始堆内存大小。默认：物理内存小于192MB时，默认为物理内存的1/2；物理内存大192MB且小于128GB时，默认为物理内存的1/4；物理内存大于等于128GB时，都为32GB。
  - -Xmx：最大堆内存大小，建议保持和初始堆内存大小一样。因为从初始堆到最大堆的过程会有一定的性能开销，而且现在内存不是稀缺资源。
  - -Xmn：年轻代大小。JDK官方建议年轻代占整个堆大小空间的3/8左右

- 根据机器类型选择合适的垃圾回收器

  - CPU单核，那么毫无疑问Serial 垃圾收集器是你唯一的选择。
  - CPU多核，关注吞吐量 ，那么选择Parallel Scavenge+Parallel Old组合（JDK8默认）。
  - CPU多核，关注用户停顿时间，JDK版本1.6或者1.7，那么选择ParNew+CMS，吞吐量降低但是低停顿。
  - CPU多核，关注用户停顿时间，JDK1.8及以上，JVM可用内存6G以上，那么选择G1

- 根据实际情况配置STW

- **调整堆内存比例**

- **调整升老年代年龄**

- **调整GC的触发条件**

  1. 频繁发生老年区回收和卡顿，应该调小 -XX:CMSInitiatingOccupancyFraction

- 垃圾回收器

  ### 新生代

  #### Serial收集器（单线程）

  - **串行GC**，**单线程**，**复制算法**，**需要STW**

  #### ParNew收集器（多线程）【**响应时间**】

  - **并行GC，多线程【根据CPU核数开启】，复制算法，需要短暂STW**

  #### Parallel Scavenge收集器（多线程）【吞吐量】

  - **并行GC，多线程【根据CPU核数开启】，复制算法，需要短暂STW**

  ### 老年代

  #### Serial Old（MSC）收集器（单线程）

  - **串行GC**，**单线程**，**标记整理算法**，**需要STW**

  #### Parallel Old收集器（多线程）【吞吐量】

  - **并行GC，多线程【根据CPU核数开启】，标记整理算法，需要短暂STW**

  #### CMS收集器（多线程/并发，**停顿延迟低**）【**最短的回收时间**】

  - **并发GC，多线程并行，算法：标记-清除算法**
  - **收集过程**
    - **初始标记**：仅标记**GcRoot节点直接关联**的对象
    - **并发标记**：**该阶段主要是做GC溯源工作**
    - **重新标记**：这个阶段主要是为了**修正“并发标记”阶段由于用户线程执行造成的GC标记变动的那部分对象**
    - **并发清除：在该阶段主要是对存活对象之外的垃圾对象进行清除**
  - 存在问题：**内存碎片，浮动垃圾**，需要加上**Serial Old**【框架匹配】















# 消息顺序消费

- 全局顺序（对应一个topic对应一个消费者单线程消费）
- 局部有序
  - 按照订单号进行哈希取余队列长度的方式将统一业务的消息同步发送到一个消息队列
  - 消费者采用拉取的方式，每次拉取的时候【锁定messagequeue】确定只有一个队列的消息可以被拉取
  - 发布消费消息，然后多线程进行消费，消费的时候获取每一个队列的锁，保证同一时刻只有一个队列的消
  - 息被消费

# 消息幂等

- Redis实现消息幂等

# nginx流量转发

- **负载均衡**

  根据客户端的 IP 地址（不同地区）计算哈希值，然后根据哈希值将请求分发到对应的后端服务集群上，这样，同一 IP 地址的客户端请求总是被分发到同一台服务器上

- **同一个集群采用lvs实现高可用**

- **Nginx 配置错误提示和回退操作**

- **Nginx 配置开发生产和灰度**

# AOP实际项目中应用

- **日志跟踪和记录**
- **安全检查**：AOP可以拦截请求，进行权限验证和安全检查，确保只有具有相应权限的用户才能访问特定的资源或执行特定的操作

# 大表查询数据优化

单表数据量2000w

## 订单系统水平和垂直拆分

## 单表索引选择

## 选错索引导致的线上慢查询事故（5000w数据）

```
 select *
  from
    sample_table
  where
      1 = 1
      and (city_id = 565)
      and (type = 13)
  order by
    id desc
  limit
    0, 1
```

### 问题原因排查（定位为选错索引）

**有idx_city_id_type联合索引和idx_1索引的」**，我们的查询条件是city_id和type，这两个索引都是能走到的，但是认为扫描行数较多【**mysql默认将limit下的扫描行数作为索引扫描的依据**；**MySQL优化器认为在limit 1的情况下，走主键索引扫描1800行左右还不用排序，使用联合索引扫描40000多左右，还需要排序**】

### Explain分析SQL语句

Explain比较重要的字段有：

- select_type : 查询类型，有简单查询、联合查询、子查询等
- key : 使用的索引
- rows : 预计需要扫描的行数
- **Extra**
  - **using filesort**：mysql不能用索引完成的排序
  - **using temporary**：查询排序使用了临时表（group by，sort）
  - **using index**：索引用于数据行查找
  - **using where**：索引用于索引键值查找
  - **using index condition**：查找使用了索引，不需要回表查询，因为要过滤的字段在索引中【mysql5.6之后支持索引下推】
    - 5.6之前，先找，回表查数据筛选，然后在进行筛选；5.6之后直接用索引列进行筛选

### 解决方案

- **强制选择索引：force index**———-暴漏在外的；索引名变化了，或者没有这个索引了，代码就要反复修改。属于硬编码
- **索引要考虑 order by 的字段**